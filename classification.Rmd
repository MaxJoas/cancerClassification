---
title: "Final Report Statistics for Biology 2"
author: "Maximilian Joas"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: zenburn
    self_contained: no
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  ioslides_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    smaller: yes
    toc: yes
    widescreen: yes
  beamer_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_tex: no
    slide_level: 2
    theme: Montpellier
    toc: yes
  word_document:
    toc: yes
    toc_depth: '3'
  slidy_presentation:
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    incremental: no
    keep_md: yes
    smaller: yes
    theme: cerulean
    toc: yes
    widescreen: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
font-import: http://fonts.googleapis.com/css?family=Risque
subtitle: "Random Forest and SVM for Cancer Classification"
font-family: Garamond
transition: linear
editor_options: 
  chunk_output_type: console
---

```{r knitr_settings, include=FALSE, echo=FALSE, eval=TRUE}
library(knitr)
options(width = 300)
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 5, 
  fig.path = 'figures/02_combinatorix_',
  fig.align = "center", 
  size = "tiny", 
  echo = TRUE, eval = TRUE, 
  warning = FALSE, message = FALSE, 
  results = TRUE, comment = "")


```


## Data Loading and Preparation
I will not go into detail in this part, since it is basiacally the same code that we did
together in class. I will only comment on things that I have changed in comparision to the work in class.
The main difference in this section is that i registered a prallel backend for multithreading and that 
I stored the class Variable "sample.labels" in an extra variable to make the code more reusable in case
we use a different dataset where the class variable has another name, we just need to change this variable once.

```{r loading_library, eval=FALSE}
library(knitr)
library(gdata)
library(ranger)
library(caret)
library(foreach)
library(doMC)
library(e1071)
library(pROC)

## register a paralell backend and define number of Threads
## Note the the numberThreads variable gets passed later to the ranger function
## this is neccessary, because ranger uses all available threads as a default and I 
## did not intend to overload the cluster.
numberThreads <- 4
doMC::registerDoMC(8)


####  Define Local directories and files ####
## Find the home directory
myHome <- Sys.getenv("HOME")

## Define the main directory for the  data and results
mainDir <- file.path(myHome, "uni/4_sem/biostatistics/report")
dir.create(path = mainDir, showWarnings = FALSE)
message("Main dir: ", mainDir)

## Define a file where we wills store the memory image
memImageFile <- file.path(mainDir, "DenBoerData_loaded.Rdata")

## Define the dir where we will download the data
destDir <- file.path(mainDir, "data")
message("Local data dir: ", destDir)

## Define a file where we will store all results
resultDir <- file.path(mainDir, "resultDir")
message("Result direcotry", resultDir)


#### Define variables for the location and name of the input files ####
## URL fo the folder containing the data fle
## Maybe refactor and pass via command line arguments later
dataURL <- "https://github.com/jvanheld/stat1/raw/master/data/DenBoer_2009/"

files <- c(
  expr = "GSE13425_Norm_Whole.tsv.gz",
  pheno = "phenoData_GSE13425.tsv.gz",
  groups = "GSE13425_group_descriptions.tsv.gz"
)



## Function that downloads input files in case they don"t exist locally yet
DownloadMyFiles <- function(files,
                            dataURL,
                            destDir) {

  ## Create local directory
  dir.create(destDir, recursive = TRUE, showWarnings = FALSE)

  for (f in files) {

    ## Destination file
    destFile <- file.path(destDir, f)

    ## Check if file exists
    if (file.exists(destFile)) {
      message("skipping download because file exists: \n", destFile)
    } else {
      sourceURL <- file.path(dataURL, f)
      download.file(url = sourceURL, destfile = destFile)
    }
  }
}




## Call the function to download the files
DownloadMyFiles(files = files, dataURL = dataURL, destDir = destDir)

kable(data.frame(list.files(destDir)),
      caption = "Content of the destination directory after file download. ")



## ---------------------------------------------------------------------
#### Load data tables ####

## Load expression table
exprTable <- read.table(file.path(destDir, files["expr"]),
                        sep = "\t",
                        header = TRUE,
                        quote = "",
                        row.names = 1)
dim(exprTable)
head(exprTable)

## Load metadescriptions (pheno table)
phenoTable <- read.table(file.path(destDir, files["pheno"]),
                         sep = "\t",
                         header = TRUE,
                         quote = "",
                         row.names = 1
                         )
dim(phenoTable)
head(phenoTable)

## for reusability provide the name of the class variable for this dataset
classVariable <- "sample.labels"

## Load group descriptions
groupDescriptions <- read.table(file.path(destDir, files["groups"]),
                                sep = "\t",
                                header = TRUE,
                                quote = "",
                                row.names = 1)
dim(groupDescriptions)
print(groupDescriptions)
kable(groupDescriptions)

```

## Prepare Data specifially for the classification task
```{r prepare_classification, eval=TRUE}
#### Prepare data for classification task ####
## check if pheno data and expression data have same order of patients
check <- names(exprTable) == rownames(phenoTable)
message("Do Pheno and Expressiondata have the same order of patients")
message(all(check = TRUE))

## Transposing the exprTable do that it has the right format for the package
exprTableTransposed <- t(exprTable)

## this prevents an error in the ranger function due to ilegal names
colnames(exprTableTransposed) <- make.names(colnames(exprTableTransposed))
```

```{r functions, eval=TRUE}
#### Feature Selection ####
## Function that selects genes based on the random forest variable importance
## It takes a vector as index variable that indicates which patients should be used
SelectFeaturesWithRandomForest <- function(trainIndex,
                                           numFeatures,
                                           verbose = TRUE
                                           ) {
    if(verbose) message("Fitting a Random Forest for feature selection")
    fit <- ranger(y = phenoTable[trainIndex, classVariable],
                  x = exprTableTransposed[trainIndex,],
                  importance = "impurity",
                  mtry = tunedMtry,
                  num.threads = numberThreads,
                  )

    if(verbose) message("Finished fitting, now extracting variable importance")
    varImportance <- fit$variable.importance
    selectedGenes <- sort(varImportance, na.last = TRUE, decreasing = TRUE)
    return(selectedGenes[1:numFeatures])
}



## Selection with leave one out cross validation
SelectRandomForestLOOCV <- function(numFeatures,
                                    verbose = FALSE) {
    res <- foreach(i = 1:nrow(exprTableTransposed)) %dopar% {
            helper <- c(1:nrow(exprTableTransposed))
            curTrainIndex <- helper[-(i)]
            curVariables <- SelectFeaturesWithRandomForest(curTrainIndex,
                                                           numFeatures,
                                                           verbose)
            return(curVariables)

    }
    names(res) <- rownames(phenoTable)
    return(res)
}



## Function that classifies patients with random forest
RandomForestClassifier <- function(numberTrees,
                                   testIndex,
                                   trainIndex,
                                   selectedCovariates,
                                   verbose = TRUE) {
    if(verbose) message("Fitting the Random Forest")
    if(verbose) message(paste0("Using ",numberTrees," trees"))
    rf.fit <- ranger(y = phenoTable[trainIndex, classVariable],
                     x = exprTableTransposed[trainIndex, selectedCovariates],
                     num.trees = numberTrees,
                     num.threads = numberThreads,
                     mtry = tunedMtry)

    testData <- t(as.data.frame(exprTableTransposed[testIndex,
                                selectedCovariates]))
    if(length(testIndex) !=1) {
        testData <- exprTableTransposed[testIndex, selectedCovariates]
        }
    if(verbose) message("Starting prediction based on the fitted model")
    predicted <- predict(rf.fit, testData)
    if(verbose) message("Finished predicting, now returning the predictions")
    predicted$predictions
    return(predicted$predictions)
}


## Function that classifies patients with SVM
SvmClassifier <- function(myKernel,
                          testIndex,
                          trainIndex,
                          selectedCovariates,
                          verbose = TRUE) {
    if(verbose) message("Starting fitting a SVM Mode")
    svm.fit <- svm(y = phenoTable[trainIndex, classVariable],
                   x = exprTableTransposed[trainIndex, selectedCovariates],
                   kernel = myKernel,
                   gamma = 0.1,
                   cost = 10,
                   type = "C-classification")
    # neccessary in case the test index has length one (loocv)
    testData <- t(as.data.frame(exprTableTransposed[testIndex,
                                                           selectedCovariates]))
    if(length(testIndex) !=1) {
        testData <- exprTableTransposed[testIndex, selectedCovariates]
    }
    predicted <- predict(svm.fit, newdata = testData)
    return(predicted)
}



#### Function for LOOCV ####
## --------------------------------------------------------------------

LOOCV <- function(FUN,
                  parameter,
                  selection,
                  verbose = FALSE) {
    res <- foreach(i = 1:nrow(exprTableTransposed)) %dopar% {
        curVariables <- names(selection[
                              rownames(exprTableTransposed)[i]][[1]])
        trainIndex <- c(1:nrow(exprTableTransposed))[-i]
        if(verbose) message("Fitting Loocv")
        res <- FUN(parameter,
                   i, -i,
                   curVariables,
                   verbose)
        res <- droplevels(res)
        names(res) <- NULL
        return(res)
    }
    if(verbose) message('returning')
    names(res) <- rownames(exprTableTransposed)
    return(unlist(res))
}

```

## Execution of code

TODO

```{r} execution_mtry}
#### EXECUTION ####
## --------------------------------------------------------------------

## first we tune the mtry parameter of the random forest model with cared
## 10 folds repeat 3 times
control <- trainControl(method = 'repeatedcv',
                        number = 10,
                        repeats = 3,
                        search = 'random')
set.seed(123)
rf.random <- train(y = phenoTable[,classVariable],
                   x = exprTableTransposed,
                   method = "ranger",
                   metric = "Accuracy",
                   trControl = control)
tunedMtry <- rf.random$finalModel$mtry
tunedMtryAllFeatures <- rf.random$finalModel$mtry

tunedMtryAllFeatures
```

## Feature Selection Execution
TODO
```{r feature_selection}
## now we select how many covariates we want to select
x <- SelectFeaturesWithRandomForest(c(1:nrow(exprTableTransposed)),
                                    nrow(exprTableTransposed))
plot(sort(x, na.last = TRUE, decreasing = TRUE))
lo <- loess(x ~ c(1:nrow(exprTableTransposed)))
out = predict(lo)
secondDer <- diff(diff(out))
maximalChangePoint <- max(secondDer)
maximalChangeIndex <- match(maximalChangePoint, secondDer)
pointHelper <- (1:nrow(phenoTable) == maximalChangeIndex)
lines(out, col = 'red', lwd = 2)
abline(v =maximalChangeIndex)
points(out[pointHelper], x = maximalChangeIndex, col = "red", pch = 22, cex = 2)
numberFeatures <- maximalChangeIndex



## finally we can perform the acutal selection
loocvSelections <- SelectRandomForestLOOCV(numberFeatures)
write.csv(loocvSelections, 'loocvSelections.csv')
```

## Tune Mtry after the Feature Selection
TOD
```{r} tuned_mtry2}
control <- trainControl(method = 'repeatedcv',
                        number = 10,
                        repeats = 3,
                        search = 'random')
set.seed(123)
rf_random <- train(y = phenoTable[,classVariable],
                   x = exprTableTransposed[,names(x)],
                   method = "ranger",
                   metric = "Accuracy",
                   trControl = control)
tunedMtryFeatureSelection <- rf_random$finalModel$mtry
```


## Classification Execution
TODO

```{r, eval=FALSE}

numberOfTrees <- c(200, 500, 1000)
kernels <- c("radial", "linear", "polynomial", "sigmoid")
allGenesSelected <- rep(list(x), nrow(exprTableTransposed))

names(allGenesSelected) <- rownames(exprTableTransposed)
selections <- list(allGenes = allGenesSelected,
                   rfSelection = loocvSelections)
resultList <- foreach(selection = names(selections), .combine = "c") %do% {
    if(selection == "rfSelection") tunedMtry = tunedMtryFeatureSelection else tunedMtry = ceiling(sqrt(ncol(exprTableTransposed)))
    message(tunedMtry)
    selData <- selections[[selection]]
    rf.comb <- foreach(numTree = numberOfTrees, .combine = "c") %do% {
        rf.loocv <- LOOCV(RandomForestClassifier, numTree, selData)
        helperLoocvFile <- paste0("rf_loocv_Selection_", selection,
                                  "_numTrees_", numTree, ".csv")
        curLoocvFile <- file.path(resultDir, helperLoocvFile)
        write.csv(rf.loocv, curLoocvFile)
        res <- list(numTree = rf.loocv)
        names(res) <- paste0(numTree)
        return(res)
    }
    svm.comb <- foreach (kern = kernels, .combine = "c") %do% {
        svm.loocv <- LOOCV(SvmClassifier, kern, selData)
        helperLoocvFile <- paste0("SVM_loocv_Selection_",
                                  selection, "_kernel_", kern, ".csv")
        curLoocvFile <- file.path(resultDir, helperLoocvFile)
        write.csv(svm.loocv, curLoocvFile)
        res <- list(kern = svm.loocv)
        names(res) <- paste0(kern)
        return(res)
    }
    svm.name <- paste0("svm ", selection)
    rf.name <- paste0("rf ", selection)
    res <- c(rfRes = rf.comb, svmRes = svm.comb)
    names(res) <- paste0(selection, names(res))
    return(res)
}


```

## Evaluation
TODO

```{r evaluation}
#TODO
evaluationResults <- foreach(res = resultList, .combine = 'rbind') %do% {
  response <- as.numeric(phenoTable[, classVariable])
  predictions <- as.numeric(pred)
  roc.res <- multiclass.roc(response, predictions)# ci = TRUE)
roc}
```
#### SVM sandbox ####

#xtab <- table(phenoTable[, classVariable], pred)
#xtab
#table(phenoTable[,classVariable])

message("Saving Image file")
message(paste(memImageFile))
save.image(memImageFile);
