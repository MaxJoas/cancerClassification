---
title: "Random Forest and SVM for Cancer Classification"
author: "Maximilian Joas"
date: "`r Sys.Date()`"
bibliography: "lib.bib"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: zenburn
    self_contained: no
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  ioslides_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    smaller: yes
    toc: yes
    widescreen: yes
  beamer_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_tex: no
    slide_level: 2
    theme: Montpellier
    toc: yes
  word_document:
    toc: yes
    toc_depth: '3'
  slidy_presentation:
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    incremental: no
    keep_md: yes
    smaller: yes
    theme: cerulean
    toc: yes
    widescreen: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
font-import: http://fonts.googleapis.com/css?family=Risque
subtitle: "Random Forest and SVM for Cancer Classification"
font-family: Garamond
transition: linear
editor_options:
  chunk_output_type: console
---

```{r knitr_settings, include=FALSE, echo=FALSE, eval=TRUE}
library(knitr)
options(width = 300)
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 5,
  fig.path = 'figures/02_combinatorix_',
  fig.align = "center",
  size = "tiny",
  echo = TRUE, eval = TRUE,
  warning = FALSE, message = FALSE,
  results = TRUE, comment = "")


```



## Background
This report is based on a 2009 study by Den Boer et al. [@den2009subtype]. The goal of this study was to improve prognostic classification of genetic subtypes of acute lymphoblastic leukaemia (ALL) in children. The kmowledge of these subtypes facilitate risk stratification and can thus be use to choose the appropriate treatment option.

In this report however, I to use the  Den Boer data set to methodically explore which methods for classification works best and how different parameters influence the classification. Precisely I use support vector machine (SVM) and random forest for classification. Additionally I use random forest for feature selection. The aim of this report is to investigate the influence of the used kernel in the SVM Classifier and the influence of the number of trees in the Random Forest Classifier. Additionally, I investigate the influence of feature selection on these two classifiers.

## Data 
The used data consits of a datatable which store information about the gene expression. Gene expression was measured with microarrays. The data has been already pre-processed before I used it. This included: filtering of barely weakly expressed genes,
log2 transformation to normalise the raw measurements,
intersample standardisation. Additionally, I worked with a data table that stored the metadata of the samples belonging to the gene expression values. In our case the information of interest is the class of the subtype of the acute lymphoblastic leukemia. Table 1 shows the freqency of the different subtypes before filtering (filtering will be done in a later step).


```{r echo=FALSE}
read_chunk('./classification.R')
```
```{r loading, eval=TRUE}
```

## Methods Theory
Due to the scope of this work, I will not be able to provide an in depth description of the methods.
The aim is to only give a very short overview, so the reader understands the key terms of the methods.

Random forest is a widely used method for classification [@diaz2006gene]. The base of a random forest model
are decision trees. A decision tree consists of multiple nodes. At each node tree is splitted into
branches depending on the value of a independent variable [@es]. In our case this would be the expression level
of a particular gene. Which variable is used at a given split is random. However, not all variables are available to sample from at each split. The number of variables available for splitting at each tree node is referred to as the mtry parameter. The end of a branch, the leaf, does not split anymore and represents the decision for a particular class. In our case that would be a cell type.
A random forest consists of multiple decision trees. Each tree gives a vote for the final decision of
the class. The class with the majority vote across all trees is the final class of a random forest.
This number of trees used in a random forest is on interest in this report. I will investigate the
influence of the number of trees on the classification accuracy. One note to parameter tuning


SVM is another well established method for classification it tries to separate the data by a hyperplane.
The goal is that data points in different classes are as far away from the hyperplane as possible. The
data points nearest to the hyperplane are called support vectors [@es]. Often times the data points are not separable in their original dimension. Nevertheless it is always possible to separate the data in a higher dimension [@hofmann2006support]. Therefore we need a way to map the data points to a higher dimension. The function used for this process is called Kernel function. There are different types of Kernels and I will investigate
the influence of the Kernel function on the classification accuracy.
In order to validate the results I implemented leave one out cross validation (see section "Methods Implementation"). The evaluation criteria was the missclassification error (MER) respectively the Accuracy of the predictions. Since I was dealing with a multiclass classification task, looking at specificity and sensitivity is not too interesting. 

In microarray studies it is common to have a high number of measurements in comparison to the number of
patients [@smallnlargep]. This is called a small n large p dataset and can lead to overfitting [@johnstone2009statistical]. Therefore, it be benifical to select only a subset of independent variables. Ideally the ones that contain the most information. In order to find these variables I also used random forest for feature selection. Precisely,
I used the impurity variable importance of the random forest. Before growing the random forest for the feature selection I tuned the mtry parameter.


## Methods Implementation
Now that I covered the theoretical basics to understand this report, it is time to present the practical
implementation of the above described methods. In order to test the classification accuracy I need to
split the data into a training data set and a validation data set. I order to have as many training and test patients as possible I decided to use leave one out cross validation as an approach. The standard way to do this would be to use the caret packages. I decided,
however, to implement the functionality myself. The reason for this is that I also wanted to use
the LOOCV approach for feature selection to avoid any bias. With my own implementation I could be sure
that I used the exact same method for feature selection and the training of the model. For my Implementation I used the foreach package for parallelization, which is highly optimized. Thus,
my implementation is also highly performant. The logic of my function is structured as follows:
I have a base function that performs the actual task, e.g feature selection or classification and another function that implements the LOOCV logic that calls the base function in each iteration.
This makes the code easy to extend, since I  only need to write a new base function for a new classification method and can use my existing function for the LOOCV logic.
The base function for classification take the parameters for the corresponding method, e.g. number of trees for random forest and the Kernel method for SVM.

For the feature selection I applied the same principles I had one function that did the actual feature selection and one function that implements the LOOCV logic and calls the feature selection function. I is also possible to specify how many feature should be selected. However I did not want to chose the number of features arbitrary. Consequently, I sorted the variable importance of all covariates and plotted it. Subsequently, I smoothed the plot in order to make it differentiable. The goal was to find the point where the variable importance drops the steepest. This point I used as a cutoff for the number of features that I selected. In order to find the point I took the highest value of the second derivative
of the smoothed line. This process is a highly reuasable ant automated process to find the number of
variables to select.




## Results and Interpretation
The result section is structured as follows: Firstly, I present the results of the feature selection process. Secondly, I will give an overview of the results of the random forest classifier for different number of trees. Subsequently, I will present the most meaningful results more in depth. I will do the same for the SVM classifier afterwards. Finally, I will compare the best classifiers across the two methods in depth. Each description of a Table / Figure is followed by a short interpreation it.



I included only classes that contained more than 30 patients. After the filtering, four classes remained. Figure 1 gives an overview of the remaining classes and how many cases each class contains.
```{r filter, eval=TRUE, fig.width=1.5, fig.height=1.5, fig.cap="Figure 1: Remaining Classes after Class Filtering. T: T-cell acute lymphoblastic leukaemia, Bo: Acute B Lymphoblastic Leukemia, Bt: TEL-AML1 , Bh: hyperdiploid childhood acute lymphoblastic leukemia"}
```
In order to find a number of genes to select I plotted the variable importance of the 200 most important genes according to the random forest variable importance. Figure 2 shows this plot together with a smoothed line of the variable importance and the point where the variable importance drops the steepest (according to the smoothed line).

```{r prepareSelect, eval=TRUE, fig.cap="Figure 2: Plot of the development of the Random Forest variable importance of the 200 most important genes. The red dots show the actual value of the variable importance, the green line smoothes this values and the blue vertical line indicated the point where the smoothed line changes the most."}
```
Accordinlgy to the plot I chose to use 50 genes, when performing the feature selection.
For the comparison of the classifiers I used two sets of selected genes: One set where I selected 50 genes and one set where I included all genes. Of course, there are many other ways to determine how many features should be included. The advandate of my approach is that it is reusable and that it quantifies the loss of importance of the features. The drawbacks are that it does not account for the total number of features in the data set and the selected number can be unfavourable in extreme cases of the distribution of the variable importance i.e. it selects only one or all genes. However, it was not the focus of this report to find a method that optimally selects the number of features. Thus, I wanted just an automated, out of the box way to do this.

```{r select, eval=TRUE}
```

For the actual comparision of the Random Forest Classifiers I used the following numbers of trees: 200, 500 and 1000. Table 3 shows an overview of the MER, Accuracy and its 95% confidence interval.
```{r overviewResultsRF, eval=TRUE}
```

 ```{r execute, eval=TRUE}
```
The accuracy of when using all genes is with 94% very high. The 95% confidence interval is also reasonably small, which gives security about the result
The number of trees seems to have no influence on the prediction accuracy, when using all genes. Only when training the Classifier with a subset of selected genes the number of trees seems to influence the prediction accuracy. Increasing the number of trees from 200 to 500, lead to an improvment of the accuracy of 10.6 percentage points. A further increase in the number of trees did not improve the prediction accuracy. The feature selection did not have an impact on the prediction when the Random Forest Classifier was trained with more than 200 trees and it decreased the accuracy when trained with 200 trees.

It is a bit unexpected that the number of trees did not have a meaningful influence on the prediction accuracy. The used numbers of trees were all rather a and thud could be already considered as nearly optimal. The reason why I used many trees, is that the data set does contain over 20,000 genes. So using fewer trees could have lead to more differences in the predcion accuracies. The fact that feature selection did not have a meaningful impact on the Classifier is not unexpected. Firstly, Random Forests can deal with a large number of covariates [@breiman2001random]. This is due to the fact that it uses only a subset of covariates at each split. Secondly, I have already used a Random Forest to select the covariates. I will go into more detail about the practical meaning of MER and accuracy at the end of the section, when comparing the two best Classifiers of this report.

In the following I will report on the detailled results of the Random Forest Classifier with 1000 trees and all genes (which yields the exact same results as the other Random Forest Classifiers expect one). Additionally, I report on the results of the Random Forest Classifier when trained with 50 genes and 200 trees. The statisitcs on the


```{r displayResult,eval=TRUE, fig.cap="**bold** Figure 1 shows a heatmap of the confusion table on the left and accuracy statistics on the right. This particular data comes from the Random Forest Classifier, when trained with 1000 trees and all genes. Notes: T: T-ALL, Bt: TEL-AML1, Bo: pre-B ALL, Bh: hyperdiploid __bold__"}
```

```{r rfSecond, eval=TRUE, fig.cap="**bold**Figure 2 shows a heatmap of the confusion table on the left and accuracy statistics on the right. This particular data comes from the Random Forest Classifier, when trained with 200 trees and 50 selected genes. T: T-ALL, Bt: TEL-AML1, Bo: pre-B ALL, Bh: hyperdiploid __bold__"}
```


Figures 1 and 2 display a heatmap of the confusion table of the classification together with statisitcs about the accurcay on the table on the right. The confusion table maps the predicted class to the actual class. Consequently, the diagonal of the table is representing correct classifcations. In each field of the table one can see the absoulute and relative frequency of the prediction of a certain subtype. Values outside of the diagonal represent a wrong prediction. In the case of Figure 1 the classifier predicted four patients to have the subtype TEL-AML1, whereas they had the type pre-B ALL in reality. Since we are deallilng with a multiclassifcation problem, False Positives and False Negatives are the same for the overall model. However I will discuss this statistics per class at the end of the section for two selected classifiers. The table on the right displays statistics of the accuracy. The accuracy is imple the percentage of correctly classified samples. Cohen's Kappa is a different measure of accuracy that accounts for the fact that correct classifications could occur by chance.

The second method of interest in this work was the SVM for classification. Again I start with an overview and discuss more detail later on. For the SVM I used four different kernel methods, namely radial, linear, polynomial and simgmoidal. As done with the Random Forest Classifier I used one time all genes and one time 50 genes, selected via the Random Forest variable Importance, as described above. Table 4 shows an overview of the MER, Accuracy and its 95% confidence interval of the SVM Classifier with different kernels.

```{r overviewResultsSVM, eval=TRUE}
```


```{r displaySVM, eval=TRUE, fig.cap="**bold**Figure 3 shows a heatmap of the confusion table on the left and accuracy statistics on the right. This particular data comes from the SVM Classifier, when trained with the radial Kernel and all. Notes: T: T-ALL, Bt:TEL-AML1, Bo: pre-B ALL, Bh: hyperdiploid __bold__"}
```



```{r displaySVM2, eval=TRUE, fig.cap="**bold**Figure 3 shows a heatmap of the confusion table on the left and accuracy statistics on the right. This particular data comes from the SVM Classifier, when trained with the sigmoid Kernel and all. Notes: T: T-ALL, Bt:TEL-AML1, Bo: pre-B ALL, Bh: hyperdiploid __bold__"}
```

TODO explain SVM in Depth
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
```{r inDepth, eval=TRUE}
```
TODO 
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.



## Conclusion
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

# References




